# 音视频开发学习

![音视频开发学习](https://github.com/ineyee/audio_video_learning/assets/16254545/da6ea891-deef-4c1e-b1bc-bb4d9d75ce64)

## 00_HelloWorld

## 01_HelloQt

## 02_HelloFFmpeg

## 03_Audio

#### 0301_RecordPCM：录制PCM数据，存进.pcm文件

###### 注意点一

录音的核心逻辑其实就是：

* （1）从设备采集一帧的数据，存进文件AVPacket（类似于文件缓冲区的作用）
* （2）将AVPacket里的数据写入文件
* （3）就这样从设备采集一帧、往文件里写入一帧、如此循环

#### 0302_RecordPCMOnSubThread：在子线程中录制PCM数据，存进.pcm文件

###### 注意点一

录音是个耗时操作，一定要在子线程里执行。

######         录音注意点二

点击停止录音时，不要粗暴地销毁录音线程，避免丢掉最后一帧的部分数据或者无法正常释放资源，而是应该设置一个条件变量去打破录音线程的循环录制条件，让录音线程录完最后一帧正常结束。

点击停止录音时，我们最好不要直接销毁掉正在录音的那条音频线程，因为直接销毁掉的话，很有可能出现的问题就是某一帧还在录、还没录完呢，你突然就把线程搞死了，这就导致那一帧是不完整的，而且run函数也会终止地不明不白，很有可能无法执行到最后正常释放资源；所以实际开发中我们停止录音的正确做法其实不是销毁音频录制线程，而是设置一个条件变量，去打破音频录制线程里那个循环录制的条件，告诉音频录制线程录完这一帧后就不要在录了，可以结束了（这里可以感觉到点击“停止录音”其实不是立马停止录音吧？而是等一小小会，等录制线程录完正在录的最后一帧，并且正常释放完资源再真正停止录音），这样就可以保证就算我们点击停止录音时那一帧录到一半也能正常录完最后一个完整的帧，同时run函数也能正常结束，该释放的资源都释放掉。

###### 注意点三

如果我们在录音过程中做了类似关闭窗口这种强制杀死App的异常操作，这依然是相当于录音过程中粗暴地销毁了录音线程，也会带来丢掉最后一帧的部分数据或者无法正常释放资源的问题，所以当我们监听到这些异常操作出现时，也要设置下条件变量，并且让录音线程wait一会再销毁内存。

如果我们正在录音的过程中点击了关闭窗口按钮怎么办呢？这个操作其实就是在销毁窗口的内存，并强制销毁掉正在录音的线程的内存，所以这个操作也会带来我们点击“停止录音”强制毁掉正在录音的那条音频线程的问题，所以我们需要在窗口销毁的时候，也调用一下音频线程的setStop(true)函数，并且让音频录制线程等下死、等音频线程最后一帧正常录完、资源也正常释放了再死，详见audiorecordthread.cpp里的析构函数。

###### 录音注意点四

录音线程本身的内存溢出问题。

好的，上面其实已经基本实现了开始录音和停止录音的逻辑，但是有一个问题：我们每点一次开始录音就会创建一个音频录制线程对象，而每个音频线程对象的生命周期都是跟当前MainWindow保持一致的，所以只有在关闭窗口的时候这些线程才会一起销毁，那如果频繁地点录音不就会导致音频线程对象越来越多，很有可能导致内存溢出吗？是的！

1、你想到的第一个办法可能是让音频线程对象懒加载，不是nullptr再创建，但这种做法对线程来说是不可行的，我们上面也说过了一个线程在执行结束后虽然它的内存还存在，但是它已经不能被再次使用了，所以没办法我们还就必须每次开始录音都创建一个新的音频录制线程；

2、1不可行的话，我们能想到的第二个办法就是在点击“停止录音”时导致音频录制线程执行结束的时候主动释放一下该音频线程对应的内存，这个办法可行的，我们只需要监听一下音频录制线程执行结束就可以了，详见audiorecordthread.cpp里的构造函数。

#### 0303_PlayPCM：播放上一步录制到的.pcm文件

###### 注意点一

播放音频是个耗时操作，一定要在子线程里执行。

###### 注意点二

播放音频的核心逻辑其实就是：

>  【文件（磁盘）】 ----音频数据----> 【文件缓冲区（程序内存）】 ----音频数据----> 【音频缓冲区（程序内存）】 ----音频数据----> 【音频播放设备的内存】

* （1）从文件里读取特定字节数的音频数据出来，存进文件缓冲区
* （2）然后音频播放库（如SDL）就会从文件缓冲区里读取数据存入它的音频缓冲区，音频缓冲区里一旦有数据了、音频播放库（如SDL）就会把数据传递给音频播放设备（如SDL的音频子系统）的内存、音频播放设备（如SDL的音频子系统）就开始播放其内存里的数据了、此时音频缓冲区里的数据就已经没用了
* （3）然后音频播放设备（如SDL的音频子系统）就一直播一直播、等快播完这波数据时、音频播放库（如SDL）就会再次触发回到向我们拉取数据，于是又开始了下一波从文件里读数据、存进文件缓冲区、存进音频缓冲区、此时上一波数据应该还没播放完、但是新的一波数据已经放在音频缓冲区里准备好了、音频播放库（如SDL）一等到音频播放设备（如SDL的音频子系统）内存里没数据了、就会把音频缓冲区里的新数据传递到给音频播放设备（如SDL的音频子系统）的内存、继续播放
* （4）就这样从文件里读一波数据、播放一波数据、连续不断、直到读完播完

###### 注意点三

文件读取线程和音频数据拉取线程是两个不同的子线程，但是两者都需要访问文件缓冲区，怎么搞？把文件缓冲区搞成全局的就可以了。

文件缓冲区的大小怎么设置？通常搞成和音频播放库（如SDL）音频缓冲区的大小一样就可以了，这样我们每从文件里读一波数据，就可以刚好塞满音频缓冲区，以字节为单位。

###### 注意点四

如何保证文件读取线程和音频数据拉取线程之间的串行关系，以确保我们确实是读一波数据、播放一波数据，再读取下一波数据播放，而不出现播放错乱？

* （1）很简单，我们只要再搞一个全局的变量，来记录文件缓冲区里到底还剩下多少数据即可，这样两个线程就都能访问到这个变量
* （2）对于文件读取线程来说，只要这个变量是大于0的，那就代表文件缓冲区里还有数据，那文件读取线程就卡住不要再读取数据了，先等音频数据拉取线程把文件缓冲区里的数据消耗完再读取
* （3）对于音频数据拉取线程来说，只要这个变量是小于等于0的，那就什么都不做、放行去让文件读取线程继续去读取下一波数据，否则就读取文件缓冲区里的数据往音频缓冲区里塞，直到把文件缓冲区里的数据读完、变量小于等于0、从而放行

###### 注意点五

记得处理最后一波数据还没播完，sdl播放资源就提前销毁的问题，处理方法：

* （1）注意文件读取线程只会等待音频数据拉取线程从文件缓冲区里搬数据这个操作，而不会等待播放器播放音频这个操作，也就是说播放器播放的同时，读文件线程已经在读取下一波数据了
* （2）因此就很有可能出现播放器还在播放最后一波数据，但是文件读取线程已经异步地判断到没有数据要读了，要销毁sdl播放资源了，这就会导致有一部分音频没正常播放出来
* （3）处理方式就是当读完最后一波数据后，播放器正在播放最后一波数据时，如果文件读取线程已经异步地判断到没有数据要读了，此时我们让文件读取线程睡眠“最后一波数据的时长”，然后再销毁sdl播放资源就可以了

###### 注意点六

就像录音那里一样，播放音频时也要注意一下“播放过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“播放线程本身的内存溢出问题”的处理。

#### 0304_PCM2WAV：.pcm文件转成.wav文件

###### 注意点一

文件格式转换操作是个耗时操作，一定要在子线程里执行。

###### 注意点二

文件格式转换的核心逻辑其实就是：

* （1）打开输入文件
* （2）打开输出文件
* （3）先从输入文件的文件头里挨个读取出音频数据的参数，然后挨个写入输出文件的文件头里
* （4）然后从输入文件里读取一段数据、写入到文件缓冲区、然后再写入到输出文件里（我们无法直接把一个文件的数据读取到另一个文件里，中间都是要经过文件缓冲区的，至于文件缓冲区定为多少个字节，可以看情况，比如我们的项目里定义为了1024个字节），就这样读一波、写一波、直到读完写完
* （5）关闭文件

###### 注意点三

怎么添加文件头？我们都知道.wav文件无非就是给.pcm文件添加一个文件头。

* 方法1：创建一个.wav文件，先把文件头写进去，然后再从.pcm文件里一段一段读取数据往.wav文件里追加，但是需要注意追加完之后，还需要通过文件的seek方法跳转到文件相应的下标处把文件头里的第2和第13部分改掉（但是我们现在这个demo是直接把已有的.pcm文件转成.wav文件，所以不需要这么做，可以直接读取到.pcm文件的大小就能得到这两个值了，这个做法其实针对的是音频录制的时候就直接存进.wav文件里的场景），因为这两部分的数据只有在把PCM数据写完之后我们才能确定它们的值，而文件头里其它部分的值我们在构建文件头的时候就能确定下来
* 方法2：创建一个.wav文件，先从.pcm文件里一段一段读取数据往.wav文件里写，等写完PCM数据后，我们不就能得到文件全部信息了嘛，文件头里的东西不就都能确定下来了吗嘛，此时再在.wav文件的前面插入44个字节的文件头

方法2看起来更好，但其实效率更低，因为文件都是一个字节一个字节存储东西的，我们如果想往文件的头部插入44个字节的数据，那就意味着PCM数据的每一个字节都得往后移动44个字节，这就跟数据结构与算法里数组的inser操作一样，因此我们此处选择方法1。

###### 注意点四

就像录音那里一样，文件格式转换时也要注意一下“转换过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“转换线程本身的内存溢出问题”的处理。

#### 0305_RecordWAV：录制PCM数据，直接存进.wav文件

###### 注意点一

录音是个耗时操作，一定要在子线程里执行。

###### 注意点二

直接录成.wav文件的核心逻辑无非就是在之前录音的基础上前面加一步、后面加一步：

* （1）在采集音频数据到文件里之前，先给文件写进去一个.wav文件头
* （2）从设备采集一帧的数据，存进文件AVPacket（类似于文件缓冲区的作用）
* （3）将AVPacket里的数据写入文件
* （4）就这样从设备采集一帧、往文件里写入一帧、如此循环
* （5）在采集完音频数据之后，返回去更新一下.wav文件头里的两个size参数

###### 注意点三

记录录音时长的话，注意不要用timer去记录录音时长，因为timer和录音线程是在两个线程里的，两者之间的同步性很成问题，所以用timer记录出来的时间绝对不准，我们应该直接用采集到的每帧音频时长累加起来才是最准确的。

当然“采集到的每帧音频时长”是在音频录制线程里才能获取到的，我们如果想把这个数据交给主线程，可以采用回调或者信号槽的方式，这里我们就采用信号槽来实现一下。

不过需要注意的是这种做法只能用在记录PCM数据的情况下，如果是传输编码后的数据就没法这么算，因为编码后数据的存储方式都应改变了。

###### 注意点四

就像录音那里一样，文件格式转换时也要注意一下“转换过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“转换线程本身的内存溢出问题”的处理。

#### 0306_PlayWAV：播放上一步录制到的.wav文件

###### 注意点一

播放音频是个耗时操作，一定要在子线程里执行。

###### 注意点二

那播放.wav文件和播放.pcm文件的核心逻辑都是一样的，唯一的区别就是：设置各种音频参数的时候不用我们写死了，而是可以从.wav文件的文件头里读取出来设置，而SDL已经提供了相关的API。

###### 注意点三

记录播放时长的话，注意不要用timer去记录播放时长，也是通过计算的方式比较准确。

不过同样需要注意的是这种做法只能用在记录PCM数据的情况下，如果是传输编码后的数据就没法这么算，因为编码后数据的存储方式都应改变了。

###### 注意点四

就像录音那里一样，文件格式转换时也要注意一下“转换过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“转换线程本身的内存溢出问题”的处理。

#### 0307_AudioResample：音频重采样

###### 注意点一

音频重采样是个耗时操作，一定要在子线程里执行。

###### 注意点二

音频重采样的核心逻辑其实就是：

* （1）打开输入文件、打开输出文件
* （2）从输入文件读取一波数据存进输入文件缓冲区
* （3）对输入文件缓冲区里的这波数据进行重采样
* （4）重采样后的数据存进输出文件缓冲区
* （5）把输出文件缓冲区里的数据存进输出文件
* （6）就这样从输入文件里读一波数据、重采样一波数据、存进输出文件、直到全部搞完
* （7）关闭输入文件、关闭输出文件

###### 注意点三

音频重采样这里得搞两个文件缓冲区，即输入文件缓冲区和输出文件缓冲区，这样处理数据更加方便，那为什么要搞俩文件缓冲区呢？

主要是因为重采样前后所需的文件缓冲区大小可能是不一样的，比如重采样前我们从文件里读取了1024个样本出来放进了文件缓冲区准备重采样，此时我们假设文件缓冲区要1000个字节，但是重采样后因为音频参数变化了，很可能需要1200个字节才能存储的下重采样后的数据，所以用两个文件缓冲区来搞更精准方便。

###### 注意点四

输入文件缓冲区和输出文件缓冲区应该分配多大？

输入文件缓冲区我们一般都是设定为能存放1024个样本。

那输出文件缓冲区应该设定为能存放多少个样本呢？这个可就不是随便写了，而是有一定的计算公式的，举个例子：

* 我们的代码里输入文件24000_s16le_1.pcm的采样率为24000Hz，然后我们设定了输入缓冲区的大小是能存放1024个样本
* 但是我们设定输出文件48000_f32le_2.pcm的采样率是48000Hz，采样率变成了原来的两倍，就意味着将来文件里的样本数也是原来的两倍，所以这次重采样其实就是通过一些算法在往原来的两个样本与样本之间插一个样本，因此如果我们还是设定输出缓冲区的样本数也是1024的话，那这一次重采样操作就无法存下原来的1024个样本 +插入的1024个样本了
* 所以输入缓冲区样本数、输入文件的采样率和输出缓冲区样本数、输出文件的采样率之间其实是存在下面关系的：

>  输入缓冲区样本数    输入文件的采样率
>  ------------------------- = ------------------------
>  输出缓冲区样本数    输出文件的采样率
>
>
>  即：输出缓冲区样本数 = 输入缓冲区样本数 * 输出文件的采样率 / 输入文件的采样率

* 当然在我们这个例子中：输出缓冲区样本数 = 1024 * 48000 / 24000 = 2048
  刚好能整除的尽但是如果我们要求输出文件的采样率为44100呢？输出缓冲区样本数 = 1024 * 44100 / 24000 = 1024 * 1.8375 = 1881.6算出个小数来，但缓冲区样本数怎么可能是小数，所以我们一般会向上取整、此时就不要是2的幂了，不然误差就太大了，直接向上取整搞成1882个样本数也差不了太多就行，从而确保一次重采样后输出缓冲区能放得下所有的样本，也正是因为这一点，我们才说“重采样确实会有误差”
* 这个公式就不消我们自己去算了，还要管什么向上取整，FFMpeg已经给我们提供好了一个函数直接用就行，详见ffmpegutil.cpp

###### 注意点五：输出缓冲区数据残留问题的处理

FFmpeg的函数注释里也说明了，由于某些原因重采样函数并不是那么完美地会把数据严谨地给我们写入到输出文件里，在最后一次处理的时候输出缓冲区可能会有数据残留，我们需要处理一下，否则输出文件就会少掉一部分音频数据详见ffmpegutil.cpp。

###### 注意点六：重采样完成后，我们怎么验证重采样的对不对呢？

* 其实能用命令行正常播放出来是不严谨的，因为数据就算差那么几十个字节我们耳朵也是听不出来
* 更严谨的做法，我们可以去查看一下转换后的数据量对不对，比如24000_s16le_1.pcm的文件大小是290,816字节，那重采样后的48000_f32le_2.pcm的文件大小就应该是290,816 * 8 = 2,326,528 字节，因为采样率是原来的2倍、位深度也是原来的2倍、通道数也是原来的2倍，总大小可不就是原来的8倍嘛，但是重采样后的音频总时长是不会变的，你不能说原来是10秒的音频，重采样后变成20秒了，这就离谱了
* 当然查看文件大小也是大致估计，不要差太多就行了，因为并不是所有的重采样都像我们上面这个例子这样刚刚好就是原来的整数倍，具体的例子见上面注意点四里的“输出缓冲区大小的设定”出现小数的情况

###### 注意点七

就像录音那里一样，文件格式转换时也要注意一下“重采样过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“重采样线程本身的内存溢出问题”的处理。

#### 0308_AACEncode：AAC编码

###### 注意点一

AAC编码是个耗时操作，一定要在子线程里执行。

###### 注意点二

AAC编码的核心逻辑其实就是：

* （1）打开输入文件、打开输出文件
* （2）从输入文件读取一波数据存进输入文件缓冲区
* （3）对输入文件缓冲区里的这波数据进行编码
* （4）编码后的数据存进输出文件缓冲区
* （5）把输出文件缓冲区里的数据存进输出文件
* （6）就这样从输入文件里读一波数据、编码一波数据、存进输出文件、直到全部搞完
* （7）关闭输入文件、关闭输出文件

###### 注意点三

跟音频重采样一样的道理，AAC编码这里得搞两个文件缓冲区，即输入文件缓冲区和输出文件缓冲区。

在重采样那个地方我们是自定义输入缓冲区和输出缓冲区的，而编码这里其实我们会用两个类AVFrame和AVPacket来达到输入缓冲区和输出缓冲区的作用。

###### 注意点四

输入文件缓冲区和输出文件缓冲区应该分配多大？

输入缓冲区能存放多少个样本：ctx->frame_size这个值是编码器建议的，不同的的编码器有不同的建议值，我们用它建议的值就行，样本帧数量（由frame_size决定），frame->format和frame->channel_layout这两个参数，纯粹就是辅编码器给我们建议值ctx->frame_size的，以保证给出来输入缓冲区的大小能存放样本数的整数倍，而不至于出现建议存储1023.5样本的情况。

至于输出文件缓冲区的大小，因为用到的是AVPacket，所以我们一开始不需要设定，编码器将来会根据编码出来的数据有多大就分配多大的AVPacket。

###### 注意点五：输出缓冲区数据残留问题的处理

FFmpeg的函数注释里也说明了，由于某些原因编码函数并不是那么完美地会把数据严谨地给我们写入到输出文件里，在最后一次处理的时候输出缓冲区可能会有数据残留，我们需要处理一下，否则输出文件就会少掉一部分音频数据详见ffmpegutil.cpp。

###### 注意点六：编码完成后，我们怎么验证重采样的对不对呢？

* 其实能用命令行正常播放出来是不严谨的，因为数据就算差那么几十个字节我们耳朵也是听不出来
* 更严谨的做法，我们可以在命令行用FFmpeg官方的工具来编码，然后对比一下字节数，编码这里字节数应该是完全对得上的

###### 注意点七

就像录音那里一样，文件格式转换时也要注意一下“编码过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“编码线程本身的内存溢出问题”的处理。

#### 0309_AACDecode：AAC解码

###### 注意点一

AAC解码是个耗时操作，一定要在子线程里执行。

###### 注意点二

AAC解码的核心逻辑其实就是：

* （1）打开输入文件、打开输出文件
* （2）从输入文件读取一波数据存进解析器输入缓冲区
* （3）解析器解析解析器输入缓冲区的数据，解析后的数据才能被解码
* （4）解析后的数据存入输入文件缓冲区
* （5）对输入文件缓冲区里的这波数据进行解码
* （6）解码后的数据存进输出文件缓冲区
* （7）把文件输出缓冲区里的数据存进输出文件
* （8）就这样从输入文件里读一波数据、编码一波数据、存进输出文件、直到全部搞完
* （9）关闭输入文件、关闭输出文件

###### 注意点三

跟AAC编码一样的道理，AAC解码这里得搞两个文件缓冲区，即输入文件缓冲区和输出文件缓冲区。

在重采样那个地方我们是自定义输入缓冲区和输出缓冲区的，而解码这里其实我们会用两个类AVFrame和AVPacket来达到输入缓冲区和输出缓冲区的作用。

但我们会发现解码这里多了一个解析器输入缓冲区，用来存放从.aac文件里读取出来的数据，解码并不像编码那样直接把数据读取出来就往pkt里放，而是会先放到这个解析器输入缓冲区里，然后这个解析器输入缓冲区里的数据要经过解析器处理后才能进入到pkt，为什么不像编码的时候那样直接搞进pkt里呢？

因为编码的时候我们用的是PCM数据，对于PCM数据我们能明确地知道它的样本是多大的，而AAC编码的数据，我们根本不知道它的一个样本有多大，只能先大概读取xx字节的数据到解析器输入缓冲区里，交给解析器去解析后才能知道样本有多大，此时再交给pkt才行。

###### 注意点四

输入文件缓冲区和输出文件缓冲区应该分配多大？解析器输入缓冲区应该分配多大？

因为我们从.aac文件里读取到的是AAC编码后的数据，所以没办法以样本为单位来设置解析器输入缓冲区的大小，只能以字节为单位，FFmpeg官方建议解析器输入缓冲区的大小是20480b / 8 = 2560字节，当然我们可以自定义其大小。

至于输入文件缓冲区和输出文件缓冲区的大小，解码的时候我们不需要设置，可见只要给定解析器输入缓冲区的大小，解码器有它们自己的解码节奏，用AVFrame和AVPacket搞就行了。

###### 注意点五：输出缓冲区数据残留问题的处理

FFmpeg的函数注释里也说明了，由于某些原因解码函数并不是那么完美地会把数据严谨地给我们写入到输出文件里，在最后一次处理的时候输出缓冲区可能会有数据残留，我们需要处理一下，否则输出文件就会少掉一部分音频数据详见ffmpegutil.cpp。

###### 注意点六：解码完成后，我们怎么验证重采样的对不对呢？

* 其实能用命令行正常播放出来是不严谨的，因为数据就算差那么几十个字节我们耳朵也是听不出来
* 更严谨的做法，我们可以在命令行用FFmpeg官方的工具来编码，然后对比一下字节数，编码这里字节数应该是完全对得上的

###### 注意点七

就像录音那里一样，文件格式转换时也要注意一下“编码过程中做了类似关闭窗口这种强制杀死App的异常操作”的处理，以及“编码线程本身的内存溢出问题”的处理。
